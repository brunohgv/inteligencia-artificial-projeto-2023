{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados e ajustes\n",
    "\n",
    "Aqui estamos carregando os dados do dataset `sao-paulo-properties-april-2019.csv` disponível no link https://www.kaggle.com/datasets/argonalyst/sao-paulo-real-estate-sale-rent-april-2019\n",
    "\n",
    "Após carregar estamos separando o dataset entre as colunas que vamos utilizar para predição (x) e a coluna que será a resposta (y)\n",
    "\n",
    "Note que foram removidas as duas últimas colunas `latitude` e `logitude`, já que estavam causando muito ruído no treinamento e impactando negativamente nos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./sao-paulo-properties-april-2019.csv\")\n",
    "# Remove latitude and logitude values since they were causing much noise\n",
    "x = df.iloc[:,1:df.columns.size-2]\n",
    "y = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação das colunas\n",
    "\n",
    "Esse dataset possui dados numéricos e categóricos. Nessa etapa estamos definindo quais colunas possuem dados numéricos e quais possuem os dados categóricos, pois eles precisam ser pre-processados de maneira diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Condo',\n",
       " 'Size',\n",
       " 'Rooms',\n",
       " 'Toilets',\n",
       " 'Suites',\n",
       " 'Parking',\n",
       " 'Elevator',\n",
       " 'Furnished',\n",
       " 'Swimming Pool',\n",
       " 'New']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(x)\n",
    "categorical_columns = categorical_columns_selector(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do preprocessados\n",
    "\n",
    "Após fazer a separação entre dados categóricos e dados numéricos, vamos definir os pre-processadores para cada um desses dados\n",
    "\n",
    "Para os dados categóricos usamos o `OneHotEncoder` e para os dados numéricos utilizamos o `StandardScaler` e colocamos numa função `ColumnTransformer` para que faça a transformação dessas colunas na faze de preprocessamento da pipeline que vamos definir adiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;District&#x27;, &#x27;Negotiation Type&#x27;,\n",
       "                                  &#x27;Property Type&#x27;]),\n",
       "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Condo&#x27;, &#x27;Size&#x27;, &#x27;Rooms&#x27;, &#x27;Toilets&#x27;, &#x27;Suites&#x27;,\n",
       "                                  &#x27;Parking&#x27;, &#x27;Elevator&#x27;, &#x27;Furnished&#x27;,\n",
       "                                  &#x27;Swimming Pool&#x27;, &#x27;New&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;District&#x27;, &#x27;Negotiation Type&#x27;,\n",
       "                                  &#x27;Property Type&#x27;]),\n",
       "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Condo&#x27;, &#x27;Size&#x27;, &#x27;Rooms&#x27;, &#x27;Toilets&#x27;, &#x27;Suites&#x27;,\n",
       "                                  &#x27;Parking&#x27;, &#x27;Elevator&#x27;, &#x27;Furnished&#x27;,\n",
       "                                  &#x27;Swimming Pool&#x27;, &#x27;New&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;District&#x27;, &#x27;Negotiation Type&#x27;, &#x27;Property Type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Condo&#x27;, &#x27;Size&#x27;, &#x27;Rooms&#x27;, &#x27;Toilets&#x27;, &#x27;Suites&#x27;, &#x27;Parking&#x27;, &#x27;Elevator&#x27;, &#x27;Furnished&#x27;, &#x27;Swimming Pool&#x27;, &#x27;New&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['District', 'Negotiation Type',\n",
       "                                  'Property Type']),\n",
       "                                ('standard_scaler', StandardScaler(),\n",
       "                                 ['Condo', 'Size', 'Rooms', 'Toilets', 'Suites',\n",
       "                                  'Parking', 'Elevator', 'Furnished',\n",
       "                                  'Swimming Pool', 'New'])])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  [\n",
    "    (\"one-hot-encoder\", categorical_preprocessor, categorical_columns),\n",
    "    (\"standard_scaler\", numerical_preprocessor, numerical_columns),\n",
    "  ]\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos algoritmos e pipelines\n",
    "\n",
    "Aqui selecionamos três algoritmos para fazer os testes com a base de dados\n",
    "\n",
    "* Multi Layer Processor Regressor\n",
    "* Linear Regression\n",
    "* Random Forest Regressor\n",
    "\n",
    "Esses algoritmos foram selecionados baseados na literatura de apoio que pode ser consultada nas referências\n",
    "\n",
    "Para cada um desses algoritmos definimos uma pipeline que inclui o pre-processador que definimos na etapa anterior, e tem como objetivo colocar os dados num formato mais adequado para o teinamento, e o algoritmo de regressão para ser processado logo após."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100), activation='relu', early_stopping=True, max_iter=1000)\n",
    "mlp_pipe = Pipeline(steps=[('pre',preprocessor),('mlpc', mlp)])\n",
    "\n",
    "line_reg = LinearRegression()\n",
    "line_reg_pipe = Pipeline(steps=[('pre', preprocessor),('linear_reg', line_reg)])\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg_pipe = Pipeline(steps=[('pre', preprocessor), ('randomforest', rf_reg)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e coleta de métricas\n",
    "\n",
    "Aqui vamos utilizar a técnica de `k_fold` que consiste em dividir a base de dados em sessões (folds) e treinar de forma individual, dando uma maior distribuição no treinamento dos dados e permitindo identificar conjuntos que possuem um melhor resultado.\n",
    "\n",
    "Definimos 5 repetições para que possamos identificar como esses treinamentos acontecem e sua consistencia a depender dos dados aleatoriamente selecionados em cada processo de fold.\n",
    "\n",
    "Então para cada algoritmo vamos treinar e coletar as métricas escolhidas\n",
    "\n",
    "* R2 Score\n",
    "* RMSE- root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import time\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "##\n",
    "## To evaluate the performance of the models, several error metrics (mean absolute error—MAE, mean square error—MSE, root mean squared error—RMSE) and goodness-of-fit (R² score) were used. This training phase was repeated for each combination of hyperparameters created in the following optimization phase.\n",
    "\n",
    "repeat = 1\n",
    "folds = 10\n",
    "mlp_r2 = []\n",
    "mlp_rmse =[]\n",
    "mlp_times = []\n",
    "linear_r2 = []\n",
    "linear_rmse = []\n",
    "linear_times = []\n",
    "rf_r2 = []\n",
    "rf_rmse = []\n",
    "rf_times = []\n",
    "\n",
    "for i in range(repeat):\n",
    "    kf = KFold(n_splits=folds)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Treinamento da MLP\n",
    "    for k, (train, test) in enumerate(kf.split(x)):\n",
    "        x_train, x_test = x.iloc[train], x.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        mlp_pipe.fit(x_train, y_train)\n",
    "        y_pred = mlp_pipe.predict(x_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        mlp_r2.append(r2)\n",
    "        mlp_rmse.append(rmse)\n",
    "\n",
    "    end_time = time.time()\n",
    "    mlp_times.append(end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Treinamento da Regressao Linear\n",
    "    for k, (train, test) in enumerate(kf.split(x)):\n",
    "        x_train, x_test = x.iloc[train], x.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        line_reg_pipe.fit(x_train, y_train)\n",
    "        y_pred = line_reg_pipe.predict(x_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        linear_r2.append(r2)\n",
    "        linear_rmse.append(rmse)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    linear_times.append(end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Treinamento da Random Forest\n",
    "    for k, (train, test) in enumerate(kf.split(x)):\n",
    "        x_train, x_test = x.iloc[train], x.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        rf_reg_pipe.fit(x_train, y_train)\n",
    "        y_pred = rf_reg_pipe.predict(x_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        rf_r2.append(r2)\n",
    "        rf_rmse.append(rmse)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    rf_times.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.9265980088880355,\n",
       " -2.5457608486277907,\n",
       " -94.09809161491499,\n",
       " 0.9011986384891914,\n",
       " 0.693362723221961,\n",
       " 0.8921071196557956,\n",
       " 0.8675885342881446,\n",
       " -186.32624184844647,\n",
       " 0.904108461947383,\n",
       " 0.8540450071072262]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
